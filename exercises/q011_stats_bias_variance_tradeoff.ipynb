{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-variance trade-off\n",
    "\n",
    "This notebook consists of 4 parts:\n",
    "- A high-level summary of the bias-variance trade-off;\n",
    "- A theoretical break-down of total model error into bias, variance, and noise;\n",
    "- A practical example computation of each of these terms using polynomial regression;\n",
    "- (Maybe) Examples to reduce bias or variance (Ridge, bagging)\n",
    "\n",
    "Sources\n",
    "- https://gist.github.com/fabgoos/6788818\n",
    "- http://scott.fortmann-roe.com/docs/BiasVariance.html\n",
    "- Book: Elements of Statistical Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We build a model using a specific algorithm on a given dataset. \n",
    "The bias-variance trade-off is about how wrong we are in trusting the algorithm vs the dataset.\n",
    "\n",
    "The total model's error can be decomposed into variance, bias, and noise.\n",
    "- **Variance** quantifies how much our model, built on this particular dataset,\n",
    "would change if we used another dataset, with the same algorithm. \n",
    "High model variance means the model is overfitting.\n",
    "- **Bias** quantifies how much a model based on the _average dataset_ \n",
    "would differ from the true label. It's about how wrong our algorithm is.\n",
    "High model bias means the model is underfitting.\n",
    "- **Noise** is intrinsic to the domain.\n",
    "Noise appears when 2 identical data points have different labels.\n",
    "Noise is measurable, but our model is independent of it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical breakdown\n",
    "\n",
    "First, let's introduce a lemma: $E[x^2] = E[(x - E(x))^2] + E[x]^2$\n",
    "\n",
    "Proof: \n",
    "$\n",
    "E[(x - E[x])^2] \n",
    "\\\\= E[x^2 - 2xE[x] + E[x]^2] \n",
    "\\\\= E[x^2] - 2E[xE[x]] + E[E[x]^2]\n",
    "\\\\= E[x^2] - E[x]^2\n",
    "$\n",
    "\n",
    "Now to the bias-variance breakdown. \n",
    "We built our model and want to predict the value of a newly-seen data point. \n",
    "We define: \n",
    "- $x$ is the feature vector of the new data point.\n",
    "- $y$ is the dependent variable, given to us in the dataset.\n",
    "- $\\epsilon$ is the noise in the DV $y$. We assume that $\\epsilon$ is normally distributed around 0.\n",
    "- $z$ is the true DV of the new datapoint, without noise, such that $y = z + \\epsilon$. \n",
    "- $\\hat{y}$ is the prediction of our model, $h$, for $y$: $\\hat{y} = h(x)$.\n",
    "\n",
    "Let's look at the expected value, over all the possible models we could build, \n",
    "of the squared error of our prediction for this new data point. \n",
    "\n",
    "$\n",
    "E[SE]\n",
    "\\\\= E[(\\hat{y}-y)^2]\n",
    "\\\\= E[\\hat{y}^2 - 2y\\hat{y} + y^2]\n",
    "\\\\= E[\\hat{y}^2] - 2E[\\hat{y}y] + E[y^2]\n",
    "$\n",
    "\n",
    "Here we apply the lemma above.\n",
    "\n",
    "$\n",
    "E[SE] \n",
    "\\\\= E[ (\\hat{y}-E[\\hat{y}])^2] + E[\\hat{y}]^2 - 2E[y]E[\\hat{y}] + E[(y-E[y])^2] + E[y]^2\n",
    "\\\\= E[ (\\hat{y}-E[\\hat{y}])^2] + ( E[\\hat{y}]-E[y])^2 + E[\\epsilon^2]\n",
    "\\\\= variance + bias^2 + noise\n",
    "$\n",
    "\n",
    "We just broke down the typical prediction error into bias, variance, and noise.\n",
    "The \"trade-off\" part is: if you held this error and noise constant, \n",
    "decreasing bias would increase variance, and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
